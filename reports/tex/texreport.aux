\relax 
\@writefile{toc}{\contentsline {section}{Abstract}{1}}
\@writefile{toc}{\contentsline {section}{Table of Contents}{2}}
\@writefile{toc}{\contentsline {section}{List of Abbreviations and Symbols}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}}
\citation{Cheriet2007}
\citation{Pesch2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Handwriting Recognition}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Pre-processing}{5}}
\citation{Dalal2005}
\citation{Dalal}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flowgraph of typical optical character recognition system. The input is an image file with two lines of text and one irrelevant object in it. The goal of each phase is to reduce the amount of processed data for the next phase until after classification the textual data is acquired in computer readable form.  }}{6}}
\newlabel{fig:flow}{{1}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Layout Analysis}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Feature Extraction}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Classification}{6}}
\citation{SAS}
\citation{Beyer}
\citation{Kelly}
\citation{ABBYY}
\citation{Smith2007a}
\citation{Breuel2007}
\citation{FreeSoftwareFoundation2016}
\citation{CognitiveTechnologies2016}
\citation{Smith2007a}
\citation{Angelica}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces For example horizontal and vertical projection histograms can be used as features to describe the shape of an object.}}{7}}
\newlabel{fig:feature}{{2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Vizualization on how k-nearest neighbours algorithm works. Blue squares and red triangles represent two groups of data. Green circle is the new data entry. Depending whether $k$ value is 3 or 5 the new entry is clasified to the class which has the most representation within the group. }}{7}}
\newlabel{fig:knn}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}State of the Art}{8}}
\citation{TheMathWorksWiener}
\citation{Sauvola2000}
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-Processing Methods}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Noise Removal}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Contrast Enhancement}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Binarization}{9}}
\citation{Li}
\citation{MathworksTextRecognition}
\@writefile{toc}{\contentsline {section}{\numberline {4}Layout Analysis Methods}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Component Property Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Stroke Thickness Variation Analysis}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Vizualization of distance transform with two different components using same color map scale. The colors represent the distance from foreground pixel to nearest background pixel. The character A has only a small amount of variation in stroke width, mainly around junction points. The other object, not representing any textual information, has noticeable variation in stroke width.  }}{10}}
\newlabel{fig:strokewidth}{{4}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Bounding Box Expansion Method}{10}}
\citation{Louloudis1}
\citation{Louloudis2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Run Length Smearing Algorithm}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The process of RLSA. Upper left image is the binarized input image. Upper right image is resulting image after RLSA is applied. In lower left image the individual lines are represented by the cyan colored boxes. Lastly in lower right image the same boxes are applied to the input image to represent individual text lines. For this case the RLSA performs well expcet for the small object under the word ``Gaitskell''.  }}{11}}
\newlabel{fig:workingrlsa}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Block Based Hough Transform Mapping}{11}}
\citation{Razak}
\citation{Louloudis1}
\citation{Louloudis2}
\citation{Louloudis1}
\citation{Louloudis1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Subgroups}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Component space partioned to 3 subsets. Here AH and AW are average height and average width of components respectively.\cite  {Louloudis1} }}{12}}
\newlabel{fig:subgroupspace}{{6}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Hough Transform Mapping}{12}}
\newlabel{sec:houghtransformmapping}{{4.5.2}{12}}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces  Red and blue lines show how $\theta $ and $\rho $ can be used to describe a line in Cartesian space. The Red line is the actual line and the blue line is used to visualize the distance $\rho $ from origin. In image processing the origin is often set in the upper-left corner. }}{13}}
\newlabel{fig:houghspace}{{7}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Additional Constraints and Techniques}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Top image: Input image with handwritten text. Bottom-left image: Subgroup 1. Block centroids hilighted. Bottom-right image: Hough transform accumulator array generated with given data points. Seven distinct lines can be detected from this accumulator array. Used image: handwritten part of IAM database entry a01-000u.  }}{14}}
\newlabel{fig:blockandacc}{{8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Resulting lines are labeled after line detection. Image displays final lines detected with current implementation. Some subgroup 2. objects intersecting multiple lines are splitted, however in some cases incorrectly. Used image: six handwritten lines from IAM database entry a01-011x  }}{14}}
\newlabel{fig:finallines}{{9}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{14}}
\citation{IAM}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Three small samples from IAM handwriting database of the same text having different writing styles.  }}{15}}
\newlabel{fig:iamsample}{{10}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experiments}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Contrast Enhancement}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Adaptive Wiener Filtering}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces The adaptive Wiener filter performed poorly only with window sizes 0 and 1. }}{16}}
\newlabel{fig:wienertest}{{11}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Binarization}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Stroke Thickness Variation Analysis}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Original input image with varying lightning on the left and the results of two different binarization approaches. The middle image is as result of binarizing the original image with constant threshold for each pixel. For the rightmost image the Sauvola binarization algorithm was used with appropriate arguments resulting in noticeably better performance. }}{17}}
\newlabel{fig:binarization}{{12}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Especially lowest threshold values for Sauvola binarization algorithm resulted in bad performance. Best results were aquired with threshold size 0.5. }}{17}}
\newlabel{fig:sauvolathreshold}{{13}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}RLSA}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Block Based Hough Transform Mapping}{17}}
\newlabel{sec:houghtransformevaluation}{{5.8}{17}}
\citation{Louloudis2}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Three rows extracted from image binarized with Sauvola algorithm using different window sizes and same $k_s$. Upper image uses $W = 5$ the lower image uses $W = 40$. Both images have same threshold value $k_s = 0.6$. }}{18}}
\newlabel{fig:sauvola540}{{14}{18}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.8.1}Optimal Values for Block Based Hough Transform Mapping}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Both parameters $n_1$ and $n_2$ were tested with values ranging from 1 to 20. Best value for $n_1$ can be seen to be 6 but no noticeably best value can be found for $n_2$. }}{19}}
\newlabel{fig:n1n2}{{15}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces $N_m$ performed best with value 7. }}{19}}
\newlabel{fig:votermargin}{{16}{19}}
\citation{Louloudis2}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Findings About Hough Transform Mapping}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Remaining Problems}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Future Work}{20}}
\bibstyle{abbrv}
\bibdata{hwr_bibliography}
\bibcite{ABBYY}{1}
\bibcite{Angelica}{2}
\bibcite{Beyer}{3}
\bibcite{Breuel2007}{4}
\bibcite{Cheriet2007}{5}
\bibcite{CognitiveTechnologies2016}{6}
\bibcite{Dalal}{7}
\bibcite{Dalal2005}{8}
\bibcite{FreeSoftwareFoundation2016}{9}
\bibcite{SAS}{10}
\bibcite{Kelly}{11}
\bibcite{Li}{12}
\bibcite{Louloudis1}{13}
\bibcite{Louloudis2}{14}
\bibcite{IAM}{15}
\bibcite{Pesch2012}{16}
\bibcite{Sauvola2000}{17}
\bibcite{Smith2007a}{18}
\bibcite{MathworksTextRecognition}{19}
\bibcite{TheMathWorksWiener}{20}
\bibcite{Razak}{21}
