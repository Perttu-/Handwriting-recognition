\relax 
\@writefile{toc}{\contentsline {section}{Abstract}{1}}
\@writefile{toc}{\contentsline {section}{Table of Contents}{2}}
\@writefile{toc}{\contentsline {section}{List of Abbreviations and Symbols}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}}
\citation{Cheriet2007}
\citation{Pesch2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Handwriting Recognition}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Pre-processing}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Layout Analysis}{5}}
\citation{Dalal2005}
\citation{Dalal}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flowgraph of typical optical character recognition system. The input is an image file with two rows of text and one irrelevant object in it. The goal of each phase is to reduce the amount of processed data for the next phase until after classification the textual data is acquired in computer readable form.  }}{6}}
\newlabel{fig:flow}{{1}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Feature Extraction}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Classification}{6}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces For example horizontal and vertical projection histograms can be used as features to describe the shape of an object.}}{6}}
\newlabel{fig:feature}{{2}{6}}
\citation{SAS}
\citation{Beyer}
\citation{Kelly}
\citation{ABBYY}
\citation{Smith2007a}
\citation{Breuel2007}
\citation{FreeSoftwareFoundation2016}
\citation{CognitiveTechnologies2016}
\citation{Smith2007a}
\citation{Angelica}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Vizualization on how k-nearest neighbours algorithm works. Blue squares and red triangles represent two groups of data. Green circle is the new data entry. Depending whether k value is 3 or 5 the new entry is clasified to the class which has the most representation within the group. }}{7}}
\newlabel{fig:knn}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}State of the Art}{7}}
\citation{TheMathWorksWiener}
\citation{Sauvola2000}
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-Processing Methods}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Noise Removal}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Contrast Enhancement}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Binarization}{9}}
\citation{Li}
\citation{MathworksTextRecognition}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Vizualization of distance transform with two different components using same color map scale. The colors represent the distance from foreground pixel to nearest background pixel. The character A has only a small amount of variation in stroke width, mainly around junction points. The other object, not representing any textual information, has noticeable variation in stroke width.  }}{10}}
\newlabel{fig:strokewidth}{{4}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {4}Layout Analysis Methods}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Component Property Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Stroke Thickness Variation Analysis}{10}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Bounding Box Expansion Method}{10}}
\citation{Louloudis1}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces The process of RLSA. Upper left image is the binarized input image. Upper right image is resulting image after RLSA is applied. In lower left image the individual rows are represented by the cyan colored boxes. Lastly in lower right image the same boxes are applied to the input image to represent individual text lines. For this case the RLSA performs well expcet for the small object under the word ``Gaitskell''.  }}{11}}
\newlabel{fig:workingrlsa}{{5}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Run Length Smearing Algorithm (RLSA)}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Block Based Hough Transform Mapping}{11}}
\citation{Razak}
\citation{Louloudis1}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Component space partioned to 3 subsets. Here AH and AW are average height and average width of components respectively. }}{12}}
\newlabel{fig:subgroupspace}{{6}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Subgroups}{12}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Hough Transform Mapping}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Left image: Subgroup 1. Block centroids hilighted. Right image: Hough transform accumulator array generated with given data points. Seven distinct lines can be detected from this accumulator array. Used image: handwritten part of IAM database entry a01-000u.  }}{13}}
\newlabel{fig:blockandacc}{{7}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Additional Constraints and Techniques}{13}}
\citation{IAM}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Detail of one result after line detection. Final lines detected with current implementation. Some objects intersecting multiple lines are splitted, however in some cases incorrectly. Used image: six handwritten lines from IAM database entry a01-011x  }}{14}}
\newlabel{fig:finallines}{{8}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Three small samples from IAM handwriting database of the same text having different writing styles.  }}{14}}
\newlabel{fig:iamsample}{{9}{14}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{14}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Original input image with varying lightning on the left and the results of two different binarization approaches. The middle image is as result of binarizing the original image with constant threshold for each pixel. For the rightmost image the Sauvola binarization algorithm was used with appropriate arguments resulting in noticeably better performance. }}{15}}
\newlabel{fig:binarization}{{10}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experiments}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Contrast Enhancement}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Binarization}{15}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}RLSA}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Stroke Thickness Variation Analysis}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}Block Based Hough Transform Mapping}{16}}
\newlabel{sec:houghtransformevaluation}{{5.7}{16}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{17}}
\bibstyle{abbrv}
\bibdata{hwr_bibliography}
\bibcite{ABBYY}{1}
\bibcite{Angelica}{2}
\bibcite{Beyer}{3}
\bibcite{Breuel2007}{4}
\bibcite{Cheriet2007}{5}
\bibcite{CognitiveTechnologies2016}{6}
\bibcite{Dalal}{7}
\bibcite{Dalal2005}{8}
\bibcite{FreeSoftwareFoundation2016}{9}
\bibcite{SAS}{10}
\bibcite{Kelly}{11}
\bibcite{Li}{12}
\bibcite{Louloudis1}{13}
\bibcite{Louloudis2}{14}
\bibcite{IAM}{15}
\bibcite{Pesch2012}{16}
\bibcite{Sauvola2000}{17}
\bibcite{Smith2007a}{18}
\bibcite{MathworksTextRecognition}{19}
\bibcite{TheMathWorksWiener}{20}
\bibcite{Razak}{21}
