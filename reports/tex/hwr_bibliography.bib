Automatically generated by Mendeley Desktop 1.16.1
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Options -> BibTeX in Mendeley Desktop

@misc{CognitiveTechnologies2016,
author = {{Cognitive Technologies}},
title = {{CuneiForm}},
howpublished = {\url{http://cognitiveforms.com/products{\_}and{\_}services/cuneiform}},
year = {2016}
}
@article{Dalal2008,
abstract = {Feature extraction is one of the basic function of handwritten script identification. It involves measuring those features of the input pattern are relevant to classification. This paper provides a review of these advances. The aim is to provide an appreciation for the range of techniques that have been developed rather than to simply list sources. Various types of features proposed for handwritten script identification include horizontal and vertical histogram, curvature information and local extreme of curvature, topological features such as loops is a group of white pixels surrounded by black ones, end points is point with exactly 1 neighbouring point, dots a cluster of say 1-3 pixels and junction is a point with more than 2 neighbours all in thinned black and white images, Parameters of polynomial or curve fitting functions, contour information where contours is the outside boundary of a pattern.},
author = {Dalal, Snehal and Malik, Latesh},
doi = {10.1109/ICETET.2008.44},
file = {::},
isbn = {9780769532677},
journal = {Proceedings - 1st International Conference on Emerging Trends in Engineering and Technology, ICETET 2008},
keywords = {Contour information,Feature extraction,Handwritten recognition,Matra/ shirorekha based feature,Topological features},
pages = {1164--1169},
title = {{A survey of methods and strategies for feature extraction in handwritten script identification}},
year = {2008}
}
@misc{Angelica,
author = {Angelica, Amara D. and Schmidhuber, J{\"{u}}rgen},
title = {{How bio-inspired deep learning keeps winning competitions}},
howpublished = {\url{http://www.kurzweilai.net/how-bio-inspired-deep-learning-keeps-winning-competitions}}
}
@misc{Itseez,
author = {Itseez},
title = {{OpenCV}},
howpublished = {\url{http://opencv.org/}}
}
@misc{Â©FKI:ResearchGrouponComputerVisionandArtificialIntelligenceIAM,
author = {{{\textcopyright} FKI: Research Group on Computer Vision and Artificial Intelligence IAM}, University of Bern},
title = {{IAM Handwriting Database}},
howpublished = {\url{http://www.iam.unibe.ch/fki/databases/iam-handwriting-database}}
}
@misc{Breuel2007,
author = {Breuel, Thomas},
title = {{Announcing the OCRopus Open Source OCR System}},
howpublished = {\url{https://web.archive.org/web/20150313051644/http://googlecode.blogspot.com/2007/04/announcing-ocropus-open-source-ocr.html}},
year = {2007}
}
@article{Smith2007a,
abstract = {The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.},
author = {Smith, Ray},
doi = {10.1109/ICDAR.2007.4376991},
file = {:home/perttu/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Smith - 2007 - An overview of the tesseract OCR engine.pdf:pdf},
isbn = {0769528228},
issn = {15205363},
journal = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
pages = {629--633},
title = {{An overview of the tesseract OCR engine}},
volume = {2},
year = {2007}
}
@book{Cheriet2007,
author = {Cheriet, M and Kharma, N and Liu, CL and Suen, C},
doi = {10.1002/9780470176535},
file = {::},
isbn = {9780471415701},
title = {{Character recognition systems: a guide for students and practitioners}},
url = {http://books.google.com/books?hl=en{\&}lr={\&}id=txYpjiK{\_}BmgC{\&}oi=fnd{\&}pg=PR7{\&}dq=CHARACTER+RECOGNITION+SYSTEMS+A+Guide+for+Students+and+Practioners{\&}ots=dEekmUxhns{\&}sig=3yFCJCGsrfQ41xzbyivS-hKhNzE},
year = {2007}
}
@misc{TheMathWorksa,
author = {{The MathWorks}, Inc.},
title = {{Image Processing Toolbox}},
howpublished = {\url{http://se.mathworks.com/products/image/}}
}
@article{Shafait2008,
author = {Shafait, Faisal and Keysers, Daniel and Breuel, Thomas M},
file = {::},
journal = {IEEE Tans. on Pattern Analysis and Machine Intelligence},
number = {6},
pages = {941--954},
title = {{Performance evaluation and benchmarking of six page segmentation algorithms}},
volume = {30},
year = {2008}
}
@misc{R.FisherS.Perkins2003,
author = {{R. Fisher, S. Perkins}, A. Walker and E. Wolfart.},
title = {{Morphology - Opening}},
howpublished = {\url{http://homepages.inf.ed.ac.uk/rbf/HIPR2/open.htm}},
year = {2003}
}
@article{Dalal2005,
abstract = {We study the question of feature sets for robust visual object recognition, adopting linear SVM based human detection as a test case. After reviewing existing edge and gradient based descriptors, we show experimentally that grids of Histograms of Oriented Gradient (HOG) descriptors significantly outperform existing feature sets for human detection. We study the influence of each stage of the computation on performance, concluding that fine-scale gradients, fine orientation binning, relatively coarse spatial binning, and high-quality local contrast normalization in overlapping descriptor blocks are all important for good results. The new approach gives near-perfect separation on the original MIT pedestrian database, so we introduce a more challenging dataset containing over 1800 annotated human images with a large range of pose variations and backgrounds.},
archivePrefix = {arXiv},
arxivId = {chao-dyn/9411012},
author = {Dalal, Navneet and Triggs, Bill},
doi = {10.1109/CVPR.2005.177},
eprint = {9411012},
file = {::},
isbn = {0-7695-2372-2},
issn = {1063-6919},
journal = {CVPR '05: Proceedings of the 2005 IEEE Computer Society Conference on Computer Vision and Pattern Recognition (CVPR'05) - Volume 1},
keywords = {human-detection,local-feature,object-detection},
pages = {886--893},
pmid = {9230594},
primaryClass = {chao-dyn},
title = {{Histograms of Oriented Gradients for Human Detection}},
url = {citeulike-article-id:3047126$\backslash$nhttp://dx.doi.org/10.1109/CVPR.2005.177},
year = {2005}
}
@article{Pesch2012,
abstract = {In this work we analyze the contribution of preprocessing steps for Latin handwriting recognition. A preprocessing pipeline based on geometric heuristics and image statistics is used. This pipeline is applied to French and English handwriting recognition in an HMM based framework. Results show that preprocessing improves recognition performance for the two tasks. The Maximum Likelihood (ML)-trained HMM system reaches a competitive WER of 16.7{\%} and outperforms many sophisticated systems for the French handwriting recognition task. The results for English handwriting are comparable to other ML-trained HMM recognizers. Using MLP preprocessing a WER of 35.3{\%} is achieved.},
author = {Pesch, Hendrik and Hamdani, Mahdi and Forster, Jens and Ney, Hermann},
doi = {10.1109/ICFHR.2012.179},
file = {::},
isbn = {978-1-4673-2262-1},
issn = {15505235},
journal = {2012 International Conference on Frontiers in Handwriting Recognition},
keywords = {Databases,English handwriting recognition,French handwriting recognition,HMM based framework,Handwriting Recognition,Handwriting recognition,Hidden Markov Models,Hidden Markov models,Latin handwriting recognition,ML-trained HMM recognizers,ML-trained HMM system,MLP preprocessing,Noise,Pipelines,Preprocessing,Text recognition,geometric heuristics,handwriting recognition,hidden Markov models,image statistics,maximum likelihood-trained HMM system,preprocessing pipeline,preprocessing techniques},
pages = {280--284},
title = {{Analysis of Preprocessing Techniques for Latin Handwriting Recognition}},
url = {http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=6424406},
year = {2012}
}
@article{Sauvola2000,
abstract = {A new method is presented for adaptive document image binarization, where the page is considered as a collection of subcomponents such as text, background and picture. The problems caused by noise, illumination and many source type-related degradations are addressed. Two new algorithms are applied to determine a local threshold for each pixel. The performance evaluation of the algorithm utilizes test images with ground-truth, evaluation metrics for binarization of textual and synthetic images, and a weight-based ranking procedure for the final result presentation. The proposed algorithms were tested with images including different types of document components and degradations. The results were compared with a number of known techniques in the literature. The benchmarking results show that the method adapts and performs well in each case qualitatively and quantitatively.},
author = {Sauvola, J. and Pietik{\"{a}}inen, M.},
doi = {10.1016/S0031-3203(99)00055-2},
file = {::},
isbn = {0818678984},
issn = {00313203},
journal = {Pattern Recognition},
keywords = {adaptive binarization,document analysis,document segmentation,document understanding,soft decision},
number = {2},
pages = {225--236},
pmid = {84262800005},
title = {{Adaptive document image binarization}},
volume = {33},
year = {2000}
}
@misc{TheMathWorks,
author = {{The MathWorks}, Inc.},
title = {{Statistics and Machine Learning Toolbox}},
howpublished = {\url{http://se.mathworks.com/products/statistics/}}
}
@misc{TheMathWorksWiener,
author = {{The MathWorks}, Inc.},
title = {{Noise Removal}},
howpublished = {\url{http://www.mathworks.com/help/images/noise-removal.html#buh9ylp-72}}
}

@article{Mithe2013,
abstract = {The Optical Character Recognition is a mobile application. It uses smart mobile phones of android platform. This paper combines the functionality of Optical Character Recognition and speech synthesizer. The objective is to develop user friendly application which performs image to speech conversion system using android phones. The OCR takes image as the input, gets text from that image and then converts it into speech. This system can be useful in various applications like banking, legal industry, other industries, and home and office automation. It mainly designed for people who are unable to read any type of text documents. In this paper, the character recognition method is presented by using OCR technology and android phone with higher quality camera},
author = {Mithe, Ravina and Indalkar, Supriya and Divekar, Nilam},
file = {::},
isbn = {2277 - 3878},
journal = {International Journal of Recent Technology and Engineering (IJRTE)},
keywords = {Binerization,Optical Character Recognition,Pattern Matching,Segmentation,Tesseract,Text Extraction},
number = {1},
pages = {72--75},
title = {{Optical Character Recognition}},
year = {2013}
}
@misc{FreeSoftwareFoundation2016,
author = {{Free Software Foundation}},
title = {{Ocrad - The GNU OCR}},
howpublished = {\url{https://www.gnu.org/software/ocrad/}},
year = {2016}
}
@article{ABBYY,
author = {ABBYY},
title = {{ABBYY FineReader}},
howpublished = {\url{http://www.abbyy.com/finereader/}}
}
@article{Dalal,
author = {Dalal, Ms Snehal},
keywords = {contour information,feature extraction,handwritten recognition,pca,topological features},
title = {{A Survey for Feature Extraction Methods in Handwritten Script Identification}},
year = {2011}
}
@misc{Kelly,
author = {Kelly, Brett},
title = {{How Evernote's Image Recognition Works}},
howpublished = {\url{https://blog.evernote.com/tech/2013/07/18/how-evernotes-image-recognition-works/}}
}

@article{Beyer,
author = {Beyer},
title = {{When Is "Nearest Neighbor" Meaningful?}},
year = {1999}
}
