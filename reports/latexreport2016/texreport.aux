\relax 
\@writefile{toc}{\contentsline {section}{Abstract}{1}}
\@writefile{toc}{\contentsline {section}{Table of Contents}{2}}
\@writefile{toc}{\contentsline {section}{List of Abbreviations and Symbols}{3}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{4}}
\citation{Cheriet2007}
\citation{Pesch2012}
\@writefile{toc}{\contentsline {section}{\numberline {2}Background}{5}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Handwriting Recognition}{5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.1}Pre-processing}{5}}
\citation{Dalal2005}
\citation{Dalal}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Flow graph of handwriting recognition systems working displaying the current research's focus. The input is an image file with seven lines of text in it. After thresholding a binarized image is acquired and after layout analysis individual lines are detected.  }}{6}}
\newlabel{fig:flow}{{1}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.2}Layout Analysis}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.3}Feature Extraction}{6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.1.4}Classification}{6}}
\citation{SAS}
\citation{Beyer}
\citation{Kelly}
\citation{ABBYY}
\citation{Smith2007a}
\citation{Breuel2007}
\citation{FreeSoftwareFoundation2016}
\citation{CognitiveTechnologies2016}
\citation{Smith2007a}
\citation{Angelica}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces For example horizontal and vertical projection histograms can be used as features to describe the shape of an object.}}{7}}
\newlabel{fig:feature}{{2}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Visualization on how k-nearest neighbors algorithm works. Blue squares and red triangles represent two groups of data. Green circle is the new data entry. Depending whether $k$ value is 3 or 5 the new entry is classified to the class which has the most representation within the group. }}{7}}
\newlabel{fig:knn}{{3}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}State of the Art}{8}}
\citation{TheMathWorksWiener}
\@writefile{toc}{\contentsline {section}{\numberline {3}Pre-Processing Methods}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Noise Removal}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Contrast Enhancement}{9}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Histogram equalization can be applied to enhance the contrast and bring out details in an image. Left image: original image. Right image: same image with equalized histogram. Image source: http://www.mathworks.com/help/images/ref/histeq.html  }}{9}}
\newlabel{fig:histeq}{{4}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Binarization}{9}}
\citation{Sauvola2000}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Visualization of adaptive thresholding done with Sauvola algorithm. Left image: input image with shadows. Middle image: threshold of each pixel visualized. Pixel which intensity value are under given threshold are set as one, otherwise they are set as zero. Right image: binarized output image.  }}{10}}
\newlabel{fig:sauvolathresholdvis}{{5}{10}}
\citation{Li}
\citation{MathworksTextRecognition}
\@writefile{toc}{\contentsline {section}{\numberline {4}Layout Analysis Methods}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Component Property Analysis}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Stroke Thickness Variation Analysis}{11}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Visualization of distance transform with two different components using same color map scale. The colors represent the distance from foreground pixel to nearest background pixel. The character A has only a small amount of variation in stroke width, mainly around junction points. The other object, not representing any textual information, has noticeable variation in stroke width.  }}{11}}
\newlabel{fig:strokewidth}{{6}{11}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Bounding Box Expansion Method}{11}}
\citation{Louloudis1}
\citation{Louloudis2}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Run Length Smearing Algorithm}{12}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces The process of RLSA. Upper left image is the binarized input image. Upper right image is resulting image after RLSA is applied. In lower left image the individual lines are represented by the cyan colored boxes. Lastly in lower right image the same boxes are applied to the input image to represent individual text lines. For this case the RLSA performs well except for the small object under the word ``Gaitskell''.  }}{12}}
\newlabel{fig:workingrlsa}{{7}{12}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Block Based Hough Transform Mapping}{12}}
\citation{Razak}
\citation{Louloudis1}
\citation{Louloudis2}
\citation{Louloudis1}
\citation{Louloudis1}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Subsets}{13}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Component space partitioned to 3 subsets. Here AH and AW are average height and average width of components respectively \cite  {Louloudis1}. }}{13}}
\newlabel{fig:subsetspace}{{8}{13}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}Hough Transform Mapping}{13}}
\newlabel{sec:houghtransformmapping}{{4.5.2}{13}}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces  Left image: Cartesian space with two data points. Red and blue lines show how $\theta $ and $\rho $ can be used to describe any line in Cartesian space. The Red line is the actual line and the perpendicular blue line is used to visualize the distance $\rho $ from origin. Right image: The green lines represent all $\theta $ and $\rho $ pairs that can produce a line which crosses either of the two data points. A line is found with the $\theta $ and $\rho $ values of the intersection point of these two sinusoidal lines. }}{14}}
\newlabel{fig:houghtransform}{{9}{14}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.3}Additional Constraints and Techniques}{14}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Left images: Input image with handwritten text and corresponding subset 1. block centroids. Right image: Hough transform accumulator array generated with given data points. Seven distinct lines can be detected from this accumulator array. Used image: handwritten part of IAM database entry a01-000u.  }}{15}}
\newlabel{fig:blockandacc}{{10}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Resulting lines are labeled after line detection. Image displays final lines detected with current implementation. Some subset 2. objects intersecting multiple lines are split, however in some cases incorrectly. Used image: six handwritten lines from IAM database entry a01-011x  }}{15}}
\newlabel{fig:finallines}{{11}{15}}
\citation{IAM}
\@writefile{toc}{\contentsline {section}{\numberline {5}Evaluation}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Dataset}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Three small samples from IAM handwriting database of the same text having different writing styles.  }}{16}}
\newlabel{fig:iamsample}{{12}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}Experiments}{16}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Contrast Enhancement}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Left image: input image. Right image: same image after histogram equalization was applied to it. Histogram equalization made rest of the recognition process more difficult by increasing the noise in the image. Used image: handwritten part of IAM database entry a01-000u. }}{17}}
\newlabel{fig:histeqfail}{{13}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.4}Adaptive Wiener Filtering}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces The adaptive Wiener filter performed poorly only with window sizes 0 and 1. }}{17}}
\newlabel{fig:wienertest}{{14}{17}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.5}Binarization}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Original input image with varying lightning on the left and the results of two different binarization approaches. The middle image is as result of binarizing the original image with constant threshold for each pixel. For the rightmost image the Sauvola binarization algorithm was used with appropriate arguments resulting in noticeably better performance. }}{18}}
\newlabel{fig:binarization}{{15}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Especially lowest threshold values for Sauvola binarization algorithm resulted in bad performance. Best results were acquired with threshold size 0.5. }}{18}}
\newlabel{fig:sauvolathreshold}{{16}{18}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.6}Stroke Thickness Variation Analysis}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Three rows extracted from image binarized with Sauvola algorithm using different window sizes and same $k_s$. Upper image uses $W = 5$ the lower image uses $W = 40$. Used threshold value $k_s = 0.6$. }}{19}}
\newlabel{fig:sauvola540}{{17}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Value 0.4 was chosen for parameter $T_{swv}$. Values higher than 0.4 didn't have much effect on the output. }}{19}}
\newlabel{fig:strokewidthresults}{{18}{19}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.7}RLSA}{19}}
\citation{Louloudis2}
\citation{Louloudis2}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces Closer inspection of these three lines produced by RLSA shows that there are many small fractions around them. The current implementation counts all of the parts as individual lines. Used threshold value $T_{RLSA} = 300$. }}{20}}
\newlabel{fig:rlsafail}{{19}{20}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.8}Block Based Hough Transform Mapping}{20}}
\newlabel{sec:houghtransformevaluation}{{5.8}{20}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.8.1}Optimal Values for Block Based Hough Transform Mapping}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces Both parameters $n_1$ and $n_2$ were tested with values ranging from 1 to 20. Best value for $n_1$ can be seen to be 6 but no noticeably best value can be found for $n_2$. }}{21}}
\newlabel{fig:n1n2}{{20}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces $N_m$ performed best with value 7. }}{21}}
\newlabel{fig:votermargin}{{21}{21}}
\citation{Louloudis2}
\citation{OpenCV}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Findings About Hough Transform Mapping}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Remaining Problems}{22}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Future Work}{22}}
\bibstyle{ieeetr}
\bibdata{hwr_bibliography}
\bibcite{Cheriet2007}{1}
\bibcite{Pesch2012}{2}
\bibcite{Dalal2005}{3}
\bibcite{Dalal}{4}
\bibcite{SAS}{5}
\bibcite{Beyer}{6}
\bibcite{Kelly}{7}
\bibcite{ABBYY}{8}
\bibcite{Smith2007a}{9}
\bibcite{Breuel2007}{10}
\bibcite{FreeSoftwareFoundation2016}{11}
\bibcite{CognitiveTechnologies2016}{12}
\bibcite{Angelica}{13}
\bibcite{TheMathWorksWiener}{14}
\bibcite{Sauvola2000}{15}
\bibcite{Li}{16}
\bibcite{MathworksTextRecognition}{17}
\bibcite{Louloudis1}{18}
\bibcite{Louloudis2}{19}
\bibcite{Razak}{20}
\bibcite{IAM}{21}
\bibcite{OpenCV}{22}
